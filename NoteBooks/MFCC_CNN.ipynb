{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "847847b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    from spela.spectrogram import Spectrogram \n",
    "    from spela.melspectrogram import Melspectrogram\n",
    "except:\n",
    "    !pip install spela\n",
    "    from spela.spectrogram import Spectrogram \n",
    "    from spela.melspectrogram import Melspectrogram\n",
    "    \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "data_dir = r\"F:\\Augmentated_Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4aa4fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wav paths\n",
    "def get_wav_paths(speaker):\n",
    "    speaker_path = data_dir + speaker\n",
    "    all_paths = [item for item in os.listdir(speaker_path)]\n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28605a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_01_path = get_wav_paths(\"/ID_01\")\n",
    "id_03_path = get_wav_paths(\"/ID_03\")\n",
    "id_04_path = get_wav_paths(\"/ID_04\")\n",
    "id_05_path = get_wav_paths(\"/ID_05\")\n",
    "id_06_path = get_wav_paths(\"/ID_06\")\n",
    "id_07_path = get_wav_paths(\"/ID_07\")\n",
    "id_09_path = get_wav_paths(\"/ID_09\")\n",
    "id_10_path = get_wav_paths(\"/ID_10\")\n",
    "id_12_path = get_wav_paths(\"/ID_12\")\n",
    "id_13_path = get_wav_paths(\"/ID_13\")\n",
    "id_14_path = get_wav_paths(\"/ID_14\")\n",
    "id_15_path = get_wav_paths(\"/ID_15\")\n",
    "id_16_path = get_wav_paths(\"/ID_16\")\n",
    "id_17_path = get_wav_paths(\"/ID_17\")\n",
    "id_19_path = get_wav_paths(\"/ID_19\")\n",
    "id_20_path = get_wav_paths(\"/ID_20\")\n",
    "id_29_path = get_wav_paths(\"/ID_29\")\n",
    "id_30_path = get_wav_paths(\"/ID_30\")\n",
    "id_31_path = get_wav_paths(\"/ID_31\")\n",
    "id_32_path = get_wav_paths(\"/ID_32\")\n",
    "id_43_path = get_wav_paths(\"/ID_43\")\n",
    "id_45_path = get_wav_paths(\"/ID_45\")\n",
    "id_48_path = get_wav_paths(\"/ID_48\")\n",
    "id_50_path = get_wav_paths(\"/ID_50\")\n",
    "id_55_path = get_wav_paths(\"/ID_55\")\n",
    "id_56_path = get_wav_paths(\"/ID_56\")\n",
    "id_58_path = get_wav_paths(\"/ID_58\")\n",
    "id_64_path = get_wav_paths(\"/ID_64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d117b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "def load_wav(wav_path, speaker):\n",
    "    with tf.compat.v1.Session(graph=tf.compat.v1.Graph()) as sess:\n",
    "        wav_path = data_dir +speaker + \"/\"+ wav_path\n",
    "        wav_filename_placeholder = tf.compat.v1.placeholder(tf.compat.v1.string, [])\n",
    "        wav_loader = tf.io.read_file(wav_filename_placeholder)\n",
    "        wav_decoder = tf.audio.decode_wav(wav_loader, desired_channels=1)\n",
    "        wav_data = sess.run(\n",
    "            wav_decoder, feed_dict={\n",
    "                wav_filename_placeholder: wav_path\n",
    "            }).audio.flatten().reshape((1, 132300))\n",
    "        sess.close()\n",
    "    return wav_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08630584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data\n",
    "def generate_training_data(speaker_paths, speaker, label):\n",
    "    wavs, labels = [], []\n",
    "    count = 0\n",
    "    for i in tqdm(speaker_paths):\n",
    "        if count>49:\n",
    "            break\n",
    "        wav = load_wav(i, speaker)\n",
    "        wavs.append(wav)\n",
    "        labels.append(label)\n",
    "        count += 1\n",
    "    return wavs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2e97295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:02<00:56, 18.87it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:19, 54.04it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:17, 61.02it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:01<00:22, 48.56it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:19, 55.20it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:18, 58.55it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:19, 56.27it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:18, 58.85it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:17, 62.45it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:14, 73.28it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:19, 54.24it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:17, 61.87it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:18, 57.93it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:16, 64.80it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:18, 58.69it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:17, 62.06it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:19, 53.99it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:19, 55.96it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:20, 51.73it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:20, 52.09it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:00<00:18, 57.88it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:01<00:24, 43.79it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:01<00:30, 34.65it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:01<00:25, 42.65it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:01<00:25, 42.11it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:01<00:26, 40.88it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:01<00:23, 44.77it/s]\n",
      "  4%|███████▋                                                                                                                                                                   | 50/1120 [00:01<00:28, 37.82it/s]\n"
     ]
    }
   ],
   "source": [
    "id_01_wavs, id_01_labels = generate_training_data(id_01_path, \"/ID_01\",0) \n",
    "id_03_wavs, id_03_labels = generate_training_data(id_03_path, \"/ID_03\",1) \n",
    "id_04_wavs, id_04_labels = generate_training_data(id_04_path, \"/ID_04\",2)\n",
    "id_05_wavs, id_05_labels = generate_training_data(id_05_path, \"/ID_05\",3)\n",
    "id_06_wavs, id_06_labels = generate_training_data(id_06_path, \"/ID_06\",4)\n",
    "id_07_wavs, id_07_labels = generate_training_data(id_07_path, \"/ID_07\",5)\n",
    "id_09_wavs, id_09_labels = generate_training_data(id_09_path, \"/ID_09\",6)\n",
    "id_10_wavs, id_10_labels = generate_training_data(id_10_path, \"/ID_10\",7)\n",
    "id_12_wavs, id_12_labels = generate_training_data(id_12_path, \"/ID_12\",8)\n",
    "id_13_wavs, id_13_labels = generate_training_data(id_13_path, \"/ID_13\",9)\n",
    "id_14_wavs, id_14_labels = generate_training_data(id_14_path, \"/ID_14\",10)\n",
    "id_15_wavs, id_15_labels = generate_training_data(id_15_path, \"/ID_15\",11)\n",
    "id_16_wavs, id_16_labels = generate_training_data(id_16_path, \"/ID_16\",12)\n",
    "id_17_wavs, id_17_labels = generate_training_data(id_17_path, \"/ID_17\",13)\n",
    "id_19_wavs, id_19_labels = generate_training_data(id_19_path, \"/ID_19\",14)\n",
    "id_20_wavs, id_20_labels = generate_training_data(id_20_path, \"/ID_20\",15)\n",
    "id_29_wavs, id_29_labels = generate_training_data(id_29_path, \"/ID_29\",16)\n",
    "id_30_wavs, id_30_labels = generate_training_data(id_30_path, \"/ID_30\",17)\n",
    "id_31_wavs, id_31_labels = generate_training_data(id_31_path, \"/ID_31\",18)\n",
    "id_32_wavs, id_32_labels = generate_training_data(id_32_path, \"/ID_32\",19)\n",
    "id_43_wavs, id_43_labels = generate_training_data(id_43_path, \"/ID_43\",20)\n",
    "id_45_wavs, id_45_labels = generate_training_data(id_45_path, \"/ID_45\",21)\n",
    "id_48_wavs, id_48_labels = generate_training_data(id_48_path, \"/ID_48\",22)\n",
    "id_50_wavs, id_50_labels = generate_training_data(id_50_path, \"/ID_50\",23)\n",
    "id_55_wavs, id_55_labels = generate_training_data(id_55_path, \"/ID_55\",24)\n",
    "id_56_wavs, id_56_labels = generate_training_data(id_56_path, \"/ID_56\",25)\n",
    "id_58_wavs, id_58_labels = generate_training_data(id_58_path, \"/ID_58\",26)\n",
    "id_64_wavs, id_64_labels = generate_training_data(id_64_path, \"/ID_64\",27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f55e01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wavs = id_01_wavs + id_03_wavs + id_04_wavs + id_05_wavs + id_06_wavs + id_07_wavs + id_09_wavs + id_10_wavs + id_12_wavs + id_13_wavs + id_14_wavs + id_15_wavs + id_16_wavs + id_17_wavs + id_19_wavs + id_20_wavs + id_29_wavs + id_30_wavs + id_31_wavs + id_32_wavs  + id_43_wavs + id_45_wavs + id_48_wavs+ id_50_wavs+ id_55_wavs+ id_56_wavs+ id_58_wavs+ id_64_wavs\n",
    "\n",
    "all_labels = id_01_labels + id_03_labels + id_04_labels + id_05_labels + id_06_labels + id_07_labels + id_09_labels + id_10_labels + id_12_labels + id_13_labels + id_14_labels + id_15_labels + id_16_labels + id_17_labels + id_19_labels + id_20_labels + id_29_labels  + id_30_labels + id_31_labels + id_32_labels  + id_43_labels + id_45_labels + id_48_labels+ id_50_labels+ id_55_labels+ id_56_labels+ id_58_labels+ id_64_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "16aa2979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 1, 132300)\n",
      "(280, 1, 132300)\n",
      "(1120, 28)\n",
      "(280, 28)\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into trainin and testing set\\\n",
    "train_wavs, test_wavs, train_labels, test_labels = train_test_split(all_wavs, all_labels, test_size=0.2)\n",
    "del all_wavs\n",
    "del all_labels\n",
    "train_x, train_y = np.array(train_wavs), np.array(train_labels)\n",
    "del train_wavs\n",
    "del train_labels\n",
    "print(train_x.shape)\n",
    "test_x, test_y = np.array(test_wavs), np.array(test_labels)\n",
    "del test_wavs\n",
    "del test_labels\n",
    "print(test_x.shape)\n",
    "train_y = tf.keras.utils.to_categorical(train_y)\n",
    "print(train_y.shape)\n",
    "test_y = tf.keras.utils.to_categorical(test_y)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec6f6953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 400\n",
      "Train 800\n",
      "Test 100\n",
      "Test 200\n"
     ]
    }
   ],
   "source": [
    "# MFCC Feature Extraction\n",
    "\n",
    "train_x_new = []\n",
    "test_x_new = []\n",
    "INPUT_SHAPE = (130,20)\n",
    "\n",
    "train_x_new = np.zeros((train_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float32)\n",
    "\n",
    "count = 0\n",
    "for sample in train_x:\n",
    "    sample = sample.reshape(132300,)\n",
    "    train_x_new[count, :, :20] = librosa.feature.mfcc(y=sample, sr=2*44100, hop_length=1024, n_fft=256, n_mfcc=20).T\n",
    "    count += 1\n",
    "    if count%400== 0:\n",
    "        print('Train', count)\n",
    "        \n",
    "test_x_new = np.zeros((test_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float32)\n",
    "\n",
    "count = 0\n",
    "for sample in test_x:\n",
    "    sample = sample.reshape(132300,)\n",
    "    test_x_new[count, :, :20] = librosa.feature.mfcc(y=sample, sr=2*44100, hop_length=1024, n_fft=256, n_mfcc=20).T\n",
    "    count += 1\n",
    "    if count%100 == 0:\n",
    "        print('Test', count) \n",
    "\n",
    "del train_x\n",
    "del test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "20916031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 130, 20, 1) (280, 130, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x_new = np.expand_dims(train_x_new, axis=3)\n",
    "test_x_new = np.expand_dims(test_x_new, axis=3)\n",
    "print(train_x_new.shape, test_x_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "31e88d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Creating a CNN Model\n",
    "\n",
    "def create_model(speech_feature):\n",
    "    model = tf.keras.Sequential()\n",
    "    if speech_feature == \"spectrogram\":\n",
    "        model.add(Spectrogram(n_dft=1024, n_hop=256, input_shape=(1,132300),\n",
    "                            return_decibel_spectrogram=True, power_spectrogram=2.0,\n",
    "                            trainable_kernel=False, name='static_stft'))\n",
    "    elif speech_feature == \"melspectrogram\":\n",
    "        model.add(Melspectrogram(sr=44100, n_mels=128,n_dft=1024, n_hop=256,\n",
    "                            input_shape=(1 , 132300),return_decibel_melgram=True,\n",
    "                            trainable_kernel=False, name='melgram'))\n",
    "    elif speech_feature == \"mfcc\":\n",
    "        model.add(tf.keras.layers.Conv2D(64, (2, 2), activation=\"relu\", input_shape=(130,20,1)))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "        model.add(tf.keras.layers.Flatten())        \n",
    "        model.add(tf.keras.layers.Dense(28, activation=\"softmax\"))\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4)\n",
    "                , loss = \"categorical_crossentropy\"\n",
    "                , metrics = [\"accuracy\"])\n",
    "        return model\n",
    "   \n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(28, activation=\"softmax\"))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate =3e-4)\n",
    "            , loss = \"categorical_crossentropy\"\n",
    "            , metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3b74d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 129, 19, 64)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 64, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 28)                1032220   \n",
      "=================================================================\n",
      "Total params: 1,032,540\n",
      "Trainable params: 1,032,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(\"mfcc\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f8962372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "run_opts = tf.compat.v1.RunOptions(report_tensor_allocations_upon_oom = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "094cb269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 280 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[32,64,129,19] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_13/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[32,64,129,19] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_13/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[metrics_18/accuracy/Identity/_667]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-3aa2a0f3da38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#...............Training mfcc_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_x_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#..............summarize history for loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\gpu2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\gpu2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    659\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\gpu2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\gpu2\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4054\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 4055\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   4056\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4057\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\gpu2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1480\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1482\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1483\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1484\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[32,64,129,19] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_13/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[32,64,129,19] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_13/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[metrics_18/accuracy/Identity/_667]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    " #...............Training mfcc_model\n",
    "\n",
    "history = model.fit(x=train_x_new, y=train_y, epochs=2, validation_data=(test_x_new, test_y),batch_size = 8)\n",
    " #..............summarize history for loss\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#................summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"C:\\Users\\ASUS\\OneDrive - BUET\\Desktop\\SR_DSP\\Test Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_01_path = get_wav_paths(\"/ID_01\")\n",
    "id_03_path = get_wav_paths(\"/ID_03\")\n",
    "id_04_path = get_wav_paths(\"/ID_04\")\n",
    "id_05_path = get_wav_paths(\"/ID_05\")\n",
    "id_06_path = get_wav_paths(\"/ID_06\")\n",
    "id_07_path = get_wav_paths(\"/ID_07\")\n",
    "id_09_path = get_wav_paths(\"/ID_09\")\n",
    "id_10_path = get_wav_paths(\"/ID_10\")\n",
    "id_12_path = get_wav_paths(\"/ID_12\")\n",
    "id_13_path = get_wav_paths(\"/ID_13\")\n",
    "id_14_path = get_wav_paths(\"/ID_14\")\n",
    "id_15_path = get_wav_paths(\"/ID_15\")\n",
    "id_16_path = get_wav_paths(\"/ID_16\")\n",
    "id_17_path = get_wav_paths(\"/ID_17\")\n",
    "id_19_path = get_wav_paths(\"/ID_19\")\n",
    "id_20_path = get_wav_paths(\"/ID_20\")\n",
    "id_29_path = get_wav_paths(\"/ID_29\")\n",
    "id_30_path = get_wav_paths(\"/ID_30\")\n",
    "id_31_path = get_wav_paths(\"/ID_31\")\n",
    "id_32_path = get_wav_paths(\"/ID_32\")\n",
    "id_43_path = get_wav_paths(\"/ID_43\")\n",
    "id_45_path = get_wav_paths(\"/ID_45\")\n",
    "id_48_path = get_wav_paths(\"/ID_48\")\n",
    "id_50_path = get_wav_paths(\"/ID_50\")\n",
    "id_55_path = get_wav_paths(\"/ID_55\")\n",
    "id_56_path = get_wav_paths(\"/ID_56\")\n",
    "id_58_path = get_wav_paths(\"/ID_58\")\n",
    "id_64_path = get_wav_paths(\"/ID_64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_01_wavs, id_01_labels = generate_training_data(id_01_path, \"/ID_01\",0) \n",
    "id_03_wavs, id_03_labels = generate_training_data(id_03_path, \"/ID_03\",1) \n",
    "id_04_wavs, id_04_labels = generate_training_data(id_04_path, \"/ID_04\",2)\n",
    "id_05_wavs, id_05_labels = generate_training_data(id_05_path, \"/ID_05\",3)\n",
    "id_06_wavs, id_06_labels = generate_training_data(id_06_path, \"/ID_06\",4)\n",
    "id_07_wavs, id_07_labels = generate_training_data(id_07_path, \"/ID_07\",5)\n",
    "id_09_wavs, id_09_labels = generate_training_data(id_09_path, \"/ID_09\",6)\n",
    "id_10_wavs, id_10_labels = generate_training_data(id_10_path, \"/ID_10\",7)\n",
    "id_12_wavs, id_12_labels = generate_training_data(id_12_path, \"/ID_12\",8)\n",
    "id_13_wavs, id_13_labels = generate_training_data(id_13_path, \"/ID_13\",9)\n",
    "id_14_wavs, id_14_labels = generate_training_data(id_14_path, \"/ID_14\",10)\n",
    "id_15_wavs, id_15_labels = generate_training_data(id_15_path, \"/ID_15\",11)\n",
    "id_16_wavs, id_16_labels = generate_training_data(id_16_path, \"/ID_16\",12)\n",
    "id_17_wavs, id_17_labels = generate_training_data(id_17_path, \"/ID_17\",13)\n",
    "id_19_wavs, id_19_labels = generate_training_data(id_19_path, \"/ID_19\",14)\n",
    "id_20_wavs, id_20_labels = generate_training_data(id_20_path, \"/ID_20\",15)\n",
    "id_29_wavs, id_29_labels = generate_training_data(id_29_path, \"/ID_29\",16)\n",
    "id_30_wavs, id_30_labels = generate_training_data(id_30_path, \"/ID_30\",17)\n",
    "id_31_wavs, id_31_labels = generate_training_data(id_31_path, \"/ID_31\",18)\n",
    "id_32_wavs, id_32_labels = generate_training_data(id_32_path, \"/ID_32\",19)\n",
    "id_43_wavs, id_43_labels = generate_training_data(id_43_path, \"/ID_43\",20)\n",
    "id_45_wavs, id_45_labels = generate_training_data(id_45_path, \"/ID_45\",21)\n",
    "id_48_wavs, id_48_labels = generate_training_data(id_48_path, \"/ID_48\",22)\n",
    "id_50_wavs, id_50_labels = generate_training_data(id_50_path, \"/ID_50\",23)\n",
    "id_55_wavs, id_55_labels = generate_training_data(id_55_path, \"/ID_55\",24)\n",
    "id_56_wavs, id_56_labels = generate_training_data(id_56_path, \"/ID_56\",25)\n",
    "id_58_wavs, id_58_labels = generate_training_data(id_58_path, \"/ID_58\",26)\n",
    "id_64_wavs, id_64_labels = generate_training_data(id_64_path, \"/ID_64\",27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00c24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wavs = id_01_wavs + id_03_wavs + id_04_wavs + id_05_wavs + id_06_wavs + id_07_wavs + id_09_wavs + id_10_wavs + id_12_wavs + id_13_wavs + id_14_wavs + id_15_wavs + id_16_wavs + id_17_wavs + id_19_wavs + id_20_wavs + id_29_wavs + id_30_wavs + id_31_wavs + id_32_wavs  + id_43_wavs + id_45_wavs + id_48_wavs+ id_50_wavs+ id_55_wavs+ id_56_wavs+ id_58_wavs+ id_64_wavs\n",
    "\n",
    "all_labels = id_01_labels + id_03_labels + id_04_labels + id_05_labels + id_06_labels + id_07_labels + id_09_labels + id_10_labels + id_12_labels + id_13_labels + id_14_labels + id_15_labels + id_16_labels + id_17_labels + id_19_labels + id_20_labels + id_29_labels  + id_30_labels + id_31_labels + id_32_labels  + id_43_labels + id_45_labels + id_48_labels+ id_50_labels+ id_55_labels+ id_56_labels+ id_58_labels+ id_64_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###..... Test set initialization......###\n",
    "test_wavs,test_labels = all_wavs, all_labels\n",
    "test_x, test_y = np.array(test_wavs), np.array(test_labels)\n",
    "test_y = tf.keras.utils.to_categorical(test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb3fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_SHAPE = (517,128)\n",
    "       \n",
    "test_x_new = np.zeros((test_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n",
    "\n",
    "count = 0\n",
    "for sample in test_wavs:\n",
    "    sample = sample.reshape(132300,)\n",
    "    test_x_new[count, :, :128] = librosa.feature.mfcc(y=sample, sr=2*44100, hop_length=256, n_fft=256, n_mfcc=128).T\n",
    "    count += 1\n",
    "    if count%300 == 0:\n",
    "        print('Test', count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72fe2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_new = np.expand_dims(test_x_new, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8926d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x_new)\n",
    "\n",
    "matrix = metrics.confusion_matrix(test_y.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print(matrix)\n",
    "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
    "plt.imshow(matrix)\n",
    "plt.colorbar()\n",
    "ticks=np.linspace(0, 37,num=38)\n",
    "plt.xticks(ticks,fontsize=6)\n",
    "plt.yticks(ticks,fontsize=6)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b227d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(test_y.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_y.argmax(axis=1), predictions.argmax(axis=1),average='macro')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_y.argmax(axis=1), predictions.argmax(axis=1),average='macro')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(test_y.argmax(axis=1), predictions.argmax(axis=1),average='macro')\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"model_mfcc.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
