{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3f8623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    from spela.spectrogram import Spectrogram \n",
    "    from spela.melspectrogram import Melspectrogram\n",
    "except:\n",
    "    !pip install spela\n",
    "    from spela.spectrogram import Spectrogram \n",
    "    from spela.melspectrogram import Melspectrogram\n",
    "    \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "data_dir = r\"C:/Users/ASUS/OneDrive - BUET/Desktop/SR_DSP/TestData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21c8ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wav paths\n",
    "def get_wav_paths(speaker):\n",
    "    speaker_path = data_dir + speaker\n",
    "    all_paths = [item for item in os.listdir(speaker_path)]\n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c101197",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_16_path = get_wav_paths(\"/ID_16\")\n",
    "id_19_path = get_wav_paths(\"/ID_19\")\n",
    "id_20_path = get_wav_paths(\"/ID_20\")\n",
    "id_21_path = get_wav_paths(\"/ID_21\")\n",
    "id_29_path = get_wav_paths(\"/ID_29\")\n",
    "id_32_path = get_wav_paths(\"/ID_32\")\n",
    "id_33_path = get_wav_paths(\"/ID_33\")\n",
    "id_35_path = get_wav_paths(\"/ID_35\")\n",
    "id_41_path = get_wav_paths(\"/ID_41\")\n",
    "id_45_path = get_wav_paths(\"/ID_45\")\n",
    "id_46_path = get_wav_paths(\"/ID_46\")\n",
    "id_49_path = get_wav_paths(\"/ID_49\")\n",
    "id_53_path = get_wav_paths(\"/ID_53\")\n",
    "id_56_path = get_wav_paths(\"/ID_56\")\n",
    "id_57_path = get_wav_paths(\"/ID_57\")\n",
    "id_59_path = get_wav_paths(\"/ID_59\")\n",
    "id_64_path = get_wav_paths(\"/ID_64\")\n",
    "id_01_path = get_wav_paths(\"/ID_01\")\n",
    "id_02_path = get_wav_paths(\"/ID_02\")\n",
    "id_04_path = get_wav_paths(\"/ID_04\")\n",
    "id_05_path = get_wav_paths(\"/ID_05\")\n",
    "id_06_path = get_wav_paths(\"/ID_06\")\n",
    "id_07_path = get_wav_paths(\"/ID_07\")\n",
    "id_10_path = get_wav_paths(\"/ID_10\")\n",
    "id_11_path = get_wav_paths(\"/ID_11\")\n",
    "id_12_path = get_wav_paths(\"/ID_12\")\n",
    "id_13_path = get_wav_paths(\"/ID_13\")\n",
    "id_25_path = get_wav_paths(\"/ID_25\")\n",
    "id_26_path = get_wav_paths(\"/ID_26\")\n",
    "id_36_path = get_wav_paths(\"/ID_36\")\n",
    "id_39_path = get_wav_paths(\"/ID_39\")\n",
    "id_42_path = get_wav_paths(\"/ID_42\")\n",
    "id_43_path = get_wav_paths(\"/ID_43\")\n",
    "id_44_path = get_wav_paths(\"/ID_44\")\n",
    "id_48_path = get_wav_paths(\"/ID_48\")\n",
    "id_61_path = get_wav_paths(\"/ID_61\")\n",
    "id_62_path = get_wav_paths(\"/ID_62\")\n",
    "id_63_path = get_wav_paths(\"/ID_63\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05c530a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "def load_wav(wav_path, speaker):\n",
    "    with tf.compat.v1.Session(graph=tf.compat.v1.Graph()) as sess:\n",
    "        wav_path = data_dir +speaker + \"/\"+ wav_path\n",
    "        wav_filename_placeholder = tf.compat.v1.placeholder(tf.compat.v1.string, [])\n",
    "        wav_loader = tf.io.read_file(wav_filename_placeholder)\n",
    "        wav_decoder = tf.audio.decode_wav(wav_loader, desired_channels=1)\n",
    "        wav_data = sess.run(\n",
    "            wav_decoder, feed_dict={\n",
    "                wav_filename_placeholder: wav_path\n",
    "            }).audio.flatten().reshape((1, 44100))\n",
    "        sess.close()\n",
    "    return wav_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b7a57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data\n",
    "def generate_training_data(speaker_paths, speaker, label):\n",
    "    wavs, labels = [], []\n",
    "    for i in tqdm(speaker_paths):\n",
    "        wav = load_wav(i, speaker)\n",
    "        wavs.append(wav)\n",
    "        labels.append(label)\n",
    "    return wavs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5c81ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 238.74it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 208.57it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 228.26it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 185.41it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 238.73it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 185.95it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 227.55it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 172.87it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 217.38it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 161.93it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 192.84it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 161.59it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 178.84it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 192.82it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 172.87it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 185.60it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 218.02it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 200.52it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 250.67it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 178.82it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 217.99it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 185.43it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 208.55it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 217.77it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 228.49it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 208.57it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 185.40it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 228.25it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 193.12it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 227.50it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 200.83it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 217.98it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 185.98it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 227.88it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 200.32it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 147.55it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 192.81it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 239.07it/s]\n"
     ]
    }
   ],
   "source": [
    "id_32_wavs, id_32_labels = generate_training_data(id_32_path, \"/ID_32\",0) \n",
    "id_33_wavs, id_33_labels = generate_training_data(id_33_path, \"/ID_33\",1) \n",
    "id_35_wavs, id_35_labels = generate_training_data(id_35_path, \"/ID_35\",2)\n",
    "id_41_wavs, id_41_labels = generate_training_data(id_41_path, \"/ID_41\",3)\n",
    "id_45_wavs, id_45_labels = generate_training_data(id_45_path, \"/ID_45\",4)\n",
    "id_16_wavs, id_16_labels = generate_training_data(id_16_path, \"/ID_16\",5)\n",
    "id_19_wavs, id_19_labels = generate_training_data(id_19_path, \"/ID_19\",6)\n",
    "id_20_wavs, id_20_labels = generate_training_data(id_20_path, \"/ID_20\",7)\n",
    "id_21_wavs, id_21_labels = generate_training_data(id_21_path, \"/ID_21\",8)\n",
    "id_29_wavs, id_29_labels = generate_training_data(id_29_path, \"/ID_29\",9)\n",
    "id_46_wavs, id_46_labels = generate_training_data(id_46_path, \"/ID_46\",10)\n",
    "id_49_wavs, id_49_labels = generate_training_data(id_49_path, \"/ID_49\",11)\n",
    "id_53_wavs, id_53_labels = generate_training_data(id_53_path, \"/ID_53\",12)\n",
    "id_56_wavs, id_56_labels = generate_training_data(id_56_path, \"/ID_56\",13)\n",
    "id_57_wavs, id_57_labels = generate_training_data(id_57_path, \"/ID_57\",14)\n",
    "id_59_wavs, id_59_labels = generate_training_data(id_59_path, \"/ID_59\",15)\n",
    "id_64_wavs, id_64_labels = generate_training_data(id_64_path, \"/ID_64\",16)\n",
    "id_01_wavs, id_01_labels = generate_training_data(id_01_path, \"/ID_01\",17)\n",
    "id_02_wavs, id_02_labels = generate_training_data(id_02_path, \"/ID_02\",18)\n",
    "id_04_wavs, id_04_labels = generate_training_data(id_04_path, \"/ID_04\",19)\n",
    "id_05_wavs, id_05_labels = generate_training_data(id_05_path, \"/ID_05\",20)\n",
    "id_06_wavs, id_06_labels = generate_training_data(id_06_path, \"/ID_06\",21)\n",
    "id_07_wavs, id_07_labels = generate_training_data(id_07_path, \"/ID_07\",22)\n",
    "id_10_wavs, id_10_labels = generate_training_data(id_10_path, \"/ID_10\",23)\n",
    "id_11_wavs, id_11_labels = generate_training_data(id_11_path, \"/ID_11\",24)\n",
    "id_12_wavs, id_12_labels = generate_training_data(id_12_path, \"/ID_12\",25)\n",
    "id_13_wavs, id_13_labels = generate_training_data(id_13_path, \"/ID_13\",26)\n",
    "id_25_wavs, id_25_labels = generate_training_data(id_25_path, \"/ID_25\",27)\n",
    "id_26_wavs, id_26_labels = generate_training_data(id_26_path, \"/ID_26\",28)\n",
    "id_36_wavs, id_36_labels = generate_training_data(id_36_path, \"/ID_36\",29)\n",
    "id_39_wavs, id_39_labels = generate_training_data(id_39_path, \"/ID_39\",30)\n",
    "id_42_wavs, id_42_labels = generate_training_data(id_42_path, \"/ID_42\",31)\n",
    "id_43_wavs, id_43_labels = generate_training_data(id_43_path, \"/ID_43\",32)\n",
    "id_44_wavs, id_44_labels = generate_training_data(id_44_path, \"/ID_44\",33)\n",
    "id_48_wavs, id_48_labels = generate_training_data(id_48_path, \"/ID_48\",34)\n",
    "id_61_wavs, id_61_labels = generate_training_data(id_61_path, \"/ID_61\",35)\n",
    "id_62_wavs, id_62_labels = generate_training_data(id_62_path, \"/ID_62\",36)\n",
    "id_63_wavs, id_63_labels = generate_training_data(id_63_path, \"/ID_63\",37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17692616",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wavs = id_32_wavs + id_33_wavs + id_35_wavs + id_41_wavs + id_45_wavs + id_16_wavs + id_19_wavs + id_20_wavs + id_21_wavs + id_29_wavs + id_46_wavs + id_49_wavs + id_53_wavs + id_56_wavs + id_57_wavs + id_59_wavs + id_64_wavs + id_01_wavs + id_02_wavs + id_04_wavs + id_05_wavs  + id_06_wavs + id_07_wavs + id_10_wavs+ id_11_wavs+ id_12_wavs+ id_13_wavs+ id_25_wavs+ id_26_wavs + id_36_wavs + id_39_wavs + id_42_wavs + id_43_wavs + id_44_wavs + id_48_wavs + id_61_wavs + id_62_wavs + id_63_wavs\n",
    "\n",
    "all_labels = id_32_labels + id_33_labels + id_35_labels + id_41_labels  + id_45_labels + id_16_labels + id_19_labels + id_20_labels + id_21_labels + id_29_labels + id_46_labels + id_49_labels + id_53_labels + id_56_labels + id_57_labels + id_59_labels + id_64_labels + id_01_labels + id_02_labels + id_04_labels + id_05_labels + id_06_labels + id_07_labels + id_10_labels + id_11_labels + id_12_labels + id_13_labels + id_25_labels + id_26_labels + id_36_labels + id_39_labels + id_42_labels + id_43_labels + id_44_labels + id_48_labels + id_61_labels + id_62_labels + id_63_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b49c1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [\"Ayan_32\",\"Razon_33\",\"Abir_35\",\"Indronil_41\",\"Sourav_45\",\"Ananna_16\",\"Redwan_19\",\"Shafin_20\",\"Shovon_21\",\"Samdani_29\",\"Rasel_46\",\"Humayom_49\",\"Saleh_53\",\"Shihab_56\",\"Prithu_57\",\"Fatin_59\",\"Sadat_64\",\"Mrinmoy_01\",\"Elin_02\",\"Aroni_04\",\"Nabila_05\",\"Subah_06\",\"Rafi_07\",\"Plabon_07\",\"Saleah_11\",\"Sabbir_12\",\"Toiyob_13\",\"Tauhid_25\",\"Murad_26\",\"Tonmoy_36\",\"Tajwar_39\",\"Monirul_42\",\"Fariza_43\",\"Shuvro_44\",\"Tanvir_48\",\"Swadesh_61\",\"Imtiaz_62\",\"Tamim_63\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef375ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into trainin and testing set\\\n",
    "train_wavs, test_wavs, train_labels, test_labels = train_test_split(all_wavs, all_labels, test_size=0.3)\n",
    "train_x, train_y = np.array(train_wavs), np.array(train_labels)\n",
    "test_x, test_y = np.array(test_wavs), np.array(test_labels)\n",
    "\n",
    "train_y = tf.keras.utils.to_categorical(train_y)\n",
    "test_y = tf.keras.utils.to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6ebed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "def create_model(speech_feature):\n",
    "    model = tf.keras.Sequential()\n",
    "    if speech_feature == \"spectrogram\":\n",
    "        model.add(Spectrogram(n_dft=1024, n_hop=256, input_shape=(1, 44100),\n",
    "                            return_decibel_spectrogram=True, power_spectrogram=2.0,\n",
    "                            trainable_kernel=False, name='static_stft'))\n",
    "    elif speech_feature == \"melspectrogram\":\n",
    "        model.add(Melspectrogram(sr=44100, n_mels=128,n_dft=1024, n_hop=256,\n",
    "                            input_shape=(1 , 44100),return_decibel_melgram=True,\n",
    "                            trainable_kernel=False, name='melgram'))\n",
    "   \n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(38, activation=\"softmax\"))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate =3e-4)\n",
    "            , loss = \"categorical_crossentropy\"\n",
    "            , metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "348fcfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "melgram (Melspectrogram)     (None, 128, 173, 1)       1116288   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 126, 171, 64)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 63, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 342720)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 38)                13023398  \n",
      "=================================================================\n",
      "Total params: 14,140,326\n",
      "Trainable params: 14,140,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# melspectrogram model\n",
    "model = create_model(\"melspectrogram\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63053f5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer sequential_13 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 1, 44100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-81b64a2b68e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# melspectrogram model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"melpectrogram\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     return func.fit(\n\u001b[0m\u001b[0;32m    796\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m                                                      steps_per_epoch, x)\n\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m     x, y, sample_weights = model._standardize_user_data(\n\u001b[0m\u001b[0;32m    620\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2314\u001b[0m     \u001b[1;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2316\u001b[1;33m       \u001b[0mall_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2317\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[1;34m(self, inputs, targets)\u001b[0m\n\u001b[0;32m   2541\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2542\u001b[0m       \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2543\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2544\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_dict_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[1;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[0;32m   2629\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m         \u001b[1;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[1;31m# Symbolic execution on symbolic tensors. We will attempt to build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;31m# the corresponding TF subgraph inside `backend.get_graph()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0m\u001b[0;32m    758\u001b[0m                                               self.name)\n\u001b[0;32m    759\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    228\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[0;32m    231\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                          \u001b[1;34m': expected min_ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer sequential_13 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 1, 44100)"
     ]
    }
   ],
   "source": [
    "# melspectrogram model\n",
    "model = create_model(\"melpectrogram\")\n",
    "model.fit(x=train_x, y=train_y, epochs=50, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87448198",
   "metadata": {},
   "outputs": [],
   "source": [
    "z,sr = librosa.load(\"C:/Users/ASUS/OneDrive - BUET/Desktop/SR_DSP/TestData/ID_59/ID_59_3.wav\",duration=1,sr=44100)\n",
    "z = np.array(z,dtype=object)\n",
    "z = z.reshape(1,44100)\n",
    "z = z[np.newaxis,:]\n",
    "y = model.predict(z)\n",
    "y = y.astype(int)\n",
    "print(y)\n",
    "idx = np.where(y == 1.0)\n",
    "print(name_list[np.int(idx[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4fe387",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x)\n",
    "\n",
    "\n",
    "matrix = metrics.confusion_matrix(test_y.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print(matrix)\n",
    "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
    "plt.imshow(matrix)\n",
    "plt.colorbar()\n",
    "ticks=np.linspace(0, 37,num=38)\n",
    "plt.xticks(ticks,fontsize=6)\n",
    "plt.yticks(ticks,fontsize=6)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import time\n",
    "\n",
    "fs = 44100  # Sample rate\n",
    "seconds = 3  # Duration of recording\n",
    "print(\"Start Speaking Now\\n\")\n",
    "time.sleep(0.5)\n",
    "print('Listening....Speak Now')\n",
    "myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=1)\n",
    "sd.wait()  # Wait until recording is finished\n",
    "print(\"Done Recording\\n\")\n",
    "\n",
    "test1 = np.array(myrecording[20000:20000+44100])\n",
    "test2 = np.array(myrecording[0:44100])\n",
    "\n",
    "test1 = test1.reshape(1,44100)\n",
    "test1 = test1[np.newaxis,:]\n",
    "test2 = test2.reshape(1,44100)\n",
    "test2 = test2[np.newaxis,:]\n",
    "\n",
    "y1 = model.predict(test1)\n",
    "y1 = y1.astype(int)\n",
    "print(y1)\n",
    "y2 = model.predict(test2)\n",
    "y2 = y2.astype(int)\n",
    "print(y2)\n",
    "\n",
    "if np.sum(y1)>0:\n",
    "\n",
    "        index1 = np.where(y1 == 1)\n",
    "         \n",
    "        index1 = np.array(index1)\n",
    "        pos = index1[1][0]\n",
    "        print(name_list[pos])\n",
    "       \n",
    "elif np.sum(y2)>0:\n",
    "        index1 = np.where(y2 == 1)\n",
    "\n",
    "        index1 = np.array(index1)\n",
    "        pos = index1[1][0]\n",
    "        print(name_list[pos])\n",
    "else:\n",
    "        print(\"Input again\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ec811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
